{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#  Libraries\n",
    "#------------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchsummary\n",
    "import os, warnings, sys\n",
    "from utils import add_flops_counting_methods, flops_to_string\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   BaseModel\n",
    "#------------------------------------------------------------------------------\n",
    "class BaseModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(BaseModel, self).__init__()\n",
    "\n",
    "\tdef summary(self, input_shape, batch_size=1, device='cpu', print_flops=False):\n",
    "\t\tprint(\"[%s] Network summary...\" % (self.__class__.__name__))\n",
    "\t\ttorchsummary.summary(self, input_size=input_shape, batch_size=batch_size, device=device)\n",
    "\t\tif print_flops:\n",
    "\t\t\tinput = torch.randn([1, *input_shape], dtype=torch.float)\n",
    "\t\t\tcounter = add_flops_counting_methods(self)\n",
    "\t\t\tcounter.eval().start_flops_count()\n",
    "\t\t\tcounter(input)\n",
    "\t\t\tprint('Flops:  {}'.format(flops_to_string(counter.compute_average_flops_cost())))\n",
    "\t\t\tprint('----------------------------------------------------------------')\n",
    "\n",
    "\tdef init_weights(self):\n",
    "\t\tprint(\"[%s] Initialize weights...\" % (self.__class__.__name__))\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "\t\t\t\tnn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\t\t\t\tif m.bias is not None:\n",
    "\t\t\t\t\tm.bias.data.zero_()\n",
    "\t\t\telif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
    "\t\t\t\tnn.init.constant_(m.bias, 0)\n",
    "\t\t\telif isinstance(m, nn.Linear):\n",
    "\t\t\t\tm.weight.data.normal_(0, 0.01)\n",
    "\t\t\t\tm.bias.data.zero_()\n",
    "\n",
    "\tdef load_pretrained_model(self, pretrained):\n",
    "\t\tif isinstance(pretrained, str):\n",
    "\t\t\tprint(\"[%s] Load pretrained model from %s\" % (self.__class__.__name__, pretrained))\n",
    "\t\t\tpretrain_dict = torch.load(pretrained, map_location='cpu')\n",
    "\t\t\tif 'state_dict' in pretrain_dict:\n",
    "\t\t\t\tpretrain_dict = pretrain_dict['state_dict']\n",
    "\t\telif isinstance(pretrained, dict):\n",
    "\t\t\tprint(\"[%s] Load pretrained model\" % (self.__class__.__name__))\n",
    "\t\t\tpretrain_dict = pretrained\n",
    "\n",
    "\t\tmodel_dict = {}\n",
    "\t\tstate_dict = self.state_dict()\n",
    "\t\tfor k, v in pretrain_dict.items():\n",
    "\t\t\tif k in state_dict:\n",
    "\t\t\t\tif state_dict[k].shape==v.shape:\n",
    "\t\t\t\t\tmodel_dict[k] = v\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(\"[%s]\"%(self.__class__.__name__), k, \"is ignored due to not matching shape\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"[%s]\"%(self.__class__.__name__), k, \"is ignored due to not matching key\")\n",
    "\t\tstate_dict.update(model_dict)\n",
    "\t\tself.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   BaseBackbone\n",
    "#------------------------------------------------------------------------------\n",
    "class BaseBackbone(BaseModel):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(BaseBackbone, self).__init__()\n",
    "\n",
    "\tdef load_pretrained_model_extended(self, pretrained):\n",
    "\t\t\"\"\"\n",
    "\t\tThis function is specifically designed for loading pretrain with different in_channels\n",
    "\t\t\"\"\"\n",
    "\t\tif isinstance(pretrained, str):\n",
    "\t\t\tprint(\"[%s] Load pretrained model from %s\" % (self.__class__.__name__, pretrained))\n",
    "\t\t\tpretrain_dict = torch.load(pretrained, map_location='cpu')\n",
    "\t\t\tif 'state_dict' in pretrain_dict:\n",
    "\t\t\t\tpretrain_dict = pretrain_dict['state_dict']\n",
    "\t\telif isinstance(pretrained, dict):\n",
    "\t\t\tprint(\"[%s] Load pretrained model\" % (self.__class__.__name__))\n",
    "\t\t\tpretrain_dict = pretrained\n",
    "\n",
    "\t\tmodel_dict = {}\n",
    "\t\tstate_dict = self.state_dict()\n",
    "\t\tfor k, v in pretrain_dict.items():\n",
    "\t\t\tif k in state_dict:\n",
    "\t\t\t\tif state_dict[k].shape!=v.shape:\n",
    "\t\t\t\t\tmodel_dict[k] = state_dict[k]\n",
    "\t\t\t\t\tmodel_dict[k][:,:3,...] = v\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmodel_dict[k] = v\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"[%s]\"%(self.__class__.__name__), k, \"is ignored\")\n",
    "\t\tstate_dict.update(model_dict)\n",
    "\t\tself.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#  BaseBackboneWrapper\n",
    "#------------------------------------------------------------------------------\n",
    "class BaseBackboneWrapper(BaseBackbone):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(BaseBackboneWrapper, self).__init__()\n",
    "\n",
    "\tdef train(self, mode=True):\n",
    "\t\tif mode:\n",
    "\t\t\tprint(\"[%s] Switch to train mode\" % (self.__class__.__name__))\n",
    "\t\telse:\n",
    "\t\t\tprint(\"[%s] Switch to eval mode\" % (self.__class__.__name__))\n",
    "\n",
    "\t\tsuper(BaseBackboneWrapper, self).train(mode)\n",
    "\t\tself._freeze_stages()\n",
    "\t\tif mode and self.norm_eval:\n",
    "\t\t\tfor module in self.modules():\n",
    "\t\t\t\t# trick: eval have effect on BatchNorm only\n",
    "\t\t\t\tif isinstance(module, nn.BatchNorm2d):\n",
    "\t\t\t\t\tmodule.eval()\n",
    "\t\t\t\telif isinstance(module, nn.Sequential):\n",
    "\t\t\t\t\tfor m in module:\n",
    "\t\t\t\t\t\tif isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "\t\t\t\t\t\t\tm.eval()\n",
    "\n",
    "\tdef init_from_imagenet(self, archname):\n",
    "\t\tpass\n",
    "\n",
    "\tdef _freeze_stages(self):\n",
    "\t\tpass\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "\treturn nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "\treturn nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Class of Basic block\n",
    "#------------------------------------------------------------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "\texpansion = 1\n",
    "\n",
    "\tdef __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "\t\tsuper(BasicBlock, self).__init__()\n",
    "\t\tself.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(planes)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\t\tself.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "\t\tself.downsample = downsample\n",
    "\t\tself.stride = stride\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresidual = x\n",
    "\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.bn1(out)\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\tout = self.conv2(out)\n",
    "\t\tout = self.bn2(out)\n",
    "\n",
    "\t\tif self.downsample is not None:\n",
    "\t\t\tresidual = self.downsample(x)\n",
    "\n",
    "\t\tout += residual\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Class of Residual bottleneck\n",
    "#------------------------------------------------------------------------------\n",
    "class Bottleneck(nn.Module):\n",
    "\texpansion = 4\n",
    "\n",
    "\tdef __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "\t\tsuper(Bottleneck, self).__init__()\n",
    "\t\tself.conv1 = conv1x1(inplanes, planes)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "\t\tself.conv2 = conv3x3(planes, planes, stride, dilation=dilation)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "\t\tself.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.downsample = downsample\n",
    "\t\tself.stride = stride\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresidual = x\n",
    "\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.bn1(out)\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\tout = self.conv2(out)\n",
    "\t\tout = self.bn2(out)\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\tout = self.conv3(out)\n",
    "\t\tout = self.bn3(out)\n",
    "\n",
    "\t\tif self.downsample is not None:\n",
    "\t\t\tresidual = self.downsample(x)\n",
    "\n",
    "\t\tout += residual\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Class of ResNet\n",
    "#------------------------------------------------------------------------------\n",
    "class ResNet(BaseBackbone):\n",
    "\tbasic_inplanes = 64\n",
    "\n",
    "\tdef __init__(self, block, layers, output_stride=32, num_classes=1000):\n",
    "\t\tsuper(ResNet, self).__init__()\n",
    "\t\tself.inplanes = self.basic_inplanes\n",
    "\t\tself.output_stride = output_stride\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\t\tif output_stride==8:\n",
    "\t\t\tstrides   = [1, 2, 1, 1]\n",
    "\t\t\tdilations = [1, 1, 2, 4]\n",
    "\t\telif output_stride==16:\n",
    "\t\t\tstrides   = [1, 2, 2, 1]\n",
    "\t\t\tdilations = [1, 1, 1, 2]\n",
    "\t\telif output_stride==32:\n",
    "\t\t\tstrides   = [1, 2, 2, 2]\n",
    "\t\t\tdilations = [1, 1, 1, 1]\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError\n",
    "\n",
    "\t\tself.conv1 = nn.Conv2d(3, self.basic_inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(self.basic_inplanes)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\t\tself.layer1 = self._make_layer(block, 1*self.basic_inplanes, num_layers=layers[0], stride=strides[0], dilation=dilations[0])\n",
    "\t\tself.layer2 = self._make_layer(block, 2*self.basic_inplanes, num_layers=layers[1], stride=strides[1], dilation=dilations[1])\n",
    "\t\tself.layer3 = self._make_layer(block, 4*self.basic_inplanes, num_layers=layers[2], stride=strides[2], dilation=dilations[2])\n",
    "\t\tself.layer4 = self._make_layer(block, 8*self.basic_inplanes, num_layers=layers[3], stride=strides[3], dilation=dilations[3])\n",
    "\n",
    "\t\tif self.num_classes is not None:\n",
    "\t\t\tself.fc = nn.Linear(8*self.basic_inplanes * block.expansion, num_classes)\n",
    "\n",
    "\t\tself.init_weights()\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Stage1\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.bn1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\t\t# Stage2\n",
    "\t\tx = self.maxpool(x)\n",
    "\t\tx = self.layer1(x)\n",
    "\t\t# Stage3\n",
    "\t\tx = self.layer2(x)\n",
    "\t\t# Stage4\n",
    "\t\tx = self.layer3(x)\n",
    "\t\t# Stage5\n",
    "\t\tx = self.layer4(x)\n",
    "\t\t# Classification\n",
    "\t\tif self.num_classes is not None:\n",
    "\t\t\tx = x.mean(dim=(2,3))\n",
    "\t\t\tx = self.fc(x)\n",
    "\t\t# Output\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "\tdef _make_layer(self, block, planes, num_layers, stride=1, dilation=1, grids=None):\n",
    "\t\t# Downsampler\n",
    "\t\tdownsample = None\n",
    "\t\tif (stride != 1) or (self.inplanes != planes * block.expansion):\n",
    "\t\t\tdownsample = nn.Sequential(\n",
    "\t\t\t\tconv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "\t\t\t\tnn.BatchNorm2d(planes * block.expansion))\n",
    "\t\t# Multi-grids\n",
    "\t\tif dilation!=1:\n",
    "\t\t\tdilations = [dilation*(2**layer_idx) for layer_idx in range(num_layers)]\n",
    "\t\telse:\n",
    "\t\t\tdilations = num_layers*[dilation]\n",
    "\t\t# Construct layers\n",
    "\t\tlayers = []\n",
    "\t\tlayers.append(block(self.inplanes, planes, stride, downsample, dilations[0]))\n",
    "\t\tself.inplanes = planes * block.expansion\n",
    "\t\tfor i in range(1, num_layers):\n",
    "\t\t\tlayers.append(block(self.inplanes, planes, dilation=dilations[i]))\n",
    "\t\treturn nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Instances of ResNet\n",
    "#------------------------------------------------------------------------------\n",
    "def resnet18(pretrained=None, **kwargs):\n",
    "\tmodel = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "\tif pretrained is not None:\n",
    "\t\tmodel._load_pretrained_model(pretrained)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=None, **kwargs):\n",
    "\tmodel = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "\tif pretrained is not None:\n",
    "\t\tmodel._load_pretrained_model(pretrained)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=None, **kwargs):\n",
    "\tmodel = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\tif pretrained is not None:\n",
    "\t\tmodel._load_pretrained_model(pretrained)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=None, **kwargs):\n",
    "\tmodel = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "\tif pretrained is not None:\n",
    "\t\tmodel._load_pretrained_model(pretrained)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=None, **kwargs):\n",
    "\tmodel = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "\tif pretrained is not None:\n",
    "\t\tmodel._load_pretrained_model(pretrained)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def get_resnet(num_layers, **kwargs):\n",
    "\tif num_layers==18:\n",
    "\t\treturn resnet18(**kwargs)\n",
    "\telif num_layers==34:\n",
    "\t\treturn resnet34(**kwargs)\n",
    "\telif num_layers==50:\n",
    "\t\treturn resnet50(**kwargs)\n",
    "\telif num_layers==101:\n",
    "\t\treturn resnet101(**kwargs)\n",
    "\telif num_layers==152:\n",
    "\t\treturn resnet152(**kwargs)\n",
    "\telse:\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#  ASSP\n",
    "#------------------------------------------------------------------------------\n",
    "class _ASPPModule(nn.Module):\n",
    "\tdef __init__(self, inplanes, planes, kernel_size, padding, dilation):\n",
    "\t\tsuper(_ASPPModule, self).__init__()\n",
    "\t\tself.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size, stride=1, padding=padding, dilation=dilation, bias=False)\n",
    "\t\tself.bn = nn.BatchNorm2d(planes)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.atrous_conv(x)\n",
    "\t\tx = self.bn(x)\n",
    "\t\treturn self.relu(x)\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "\tdef __init__(self, output_stride, inplanes):\n",
    "\t\tsuper(ASPP, self).__init__()\n",
    "\n",
    "\t\tif output_stride == 16:\n",
    "\t\t\tdilations = [1, 6, 12, 18]\n",
    "\t\telif output_stride == 8:\n",
    "\t\t\tdilations = [1, 12, 24, 36]\n",
    "\n",
    "\t\tself.aspp1 = _ASPPModule(inplanes, 256, 1, padding=0, dilation=dilations[0])\n",
    "\t\tself.aspp2 = _ASPPModule(inplanes, 256, 3, padding=dilations[1], dilation=dilations[1])\n",
    "\t\tself.aspp3 = _ASPPModule(inplanes, 256, 3, padding=dilations[2], dilation=dilations[2])\n",
    "\t\tself.aspp4 = _ASPPModule(inplanes, 256, 3, padding=dilations[3], dilation=dilations[3])\n",
    "\n",
    "\t\tself.global_avg_pool = nn.Sequential(\n",
    "\t\t\tnn.AdaptiveAvgPool2d((1, 1)),\n",
    "\t\t\tnn.Conv2d(inplanes, 256, 1, stride=1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t)\n",
    "\t\tself.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(256)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx1 = self.aspp1(x)\n",
    "\t\tx2 = self.aspp2(x)\n",
    "\t\tx3 = self.aspp3(x)\n",
    "\t\tx4 = self.aspp4(x)\n",
    "\t\tx5 = self.global_avg_pool(x)\n",
    "\t\tx5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\t\tx = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.bn1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\t\treturn self.dropout(x)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#  Decoder\n",
    "#------------------------------------------------------------------------------\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, num_classes, low_level_inplanes):\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\n",
    "\t\tself.conv1 = nn.Conv2d(low_level_inplanes, 48, 1, bias=False)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(48)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.last_conv = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Dropout(0.5),\n",
    "\t\t\tnn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Dropout(0.1),\n",
    "\t\t\tnn.Conv2d(256, num_classes, kernel_size=1, stride=1),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x, low_level_feat):\n",
    "\t\tlow_level_feat = self.conv1(low_level_feat)\n",
    "\t\tlow_level_feat = self.bn1(low_level_feat)\n",
    "\t\tlow_level_feat = self.relu(low_level_feat)\n",
    "\n",
    "\t\tx = F.interpolate(x, size=low_level_feat.size()[2:], mode='bilinear', align_corners=True)\n",
    "\t\tx = torch.cat((x, low_level_feat), dim=1)\n",
    "\t\tx = self.last_conv(x)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#  DeepLabV3Plus\n",
    "#------------------------------------------------------------------------------\n",
    "class DeepLabV3Plus(BaseModel):\n",
    "\tdef __init__(self, backbone='resnet50', output_stride=16, num_classes=2, freeze_bn=False, pretrained_backbone=None):\n",
    "\t\tsuper(DeepLabV3Plus, self).__init__()\n",
    "\t\tif 'resnet' in backbone:\n",
    "\t\t\tif backbone=='resnet18':\n",
    "\t\t\t\tnum_layers = 18\n",
    "\t\t\t\tinplanes = 512\n",
    "\t\t\t\tlow_level_inplanes = 64\n",
    "\t\t\telif backbone=='resnet34':\n",
    "\t\t\t\tnum_layers = 34\n",
    "\t\t\t\tinplanes = 512\n",
    "\t\t\t\tlow_level_inplanes = 64\n",
    "\t\t\telif backbone=='resnet50':\n",
    "\t\t\t\tnum_layers = 50\n",
    "\t\t\t\tinplanes = 2048\n",
    "\t\t\t\tlow_level_inplanes = 256\n",
    "\t\t\telif backbone=='resnet101':\n",
    "\t\t\t\tnum_layers = 101\n",
    "\t\t\t\tinplanes = 2048\n",
    "\t\t\t\tlow_level_inplanes = 256\n",
    "\n",
    "\t\t\tself.backbone = get_resnet(num_layers=num_layers, num_classes=None)\n",
    "\t\t\tself._run_backbone = self._run_backbone_resnet\n",
    "\t\t\tself.aspp = ASPP(output_stride, inplanes=inplanes)\n",
    "\t\t\tself.decoder = Decoder(num_classes, low_level_inplanes=low_level_inplanes)\n",
    "\n",
    "\t\telif backbone=='vgg16':\n",
    "\t\t\tself.backbone = VGG.vgg16_bn(output_stride=output_stride)\n",
    "\t\t\tself.aspp = ASPP(output_stride, inplanes=512)\n",
    "\t\t\tself.decoder = Decoder(num_classes, low_level_inplanes=256)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError\n",
    "\n",
    "\t\tself._init_weights()\n",
    "\t\tif pretrained_backbone is not None:\n",
    "\t\t\tself.backbone._load_pretrained_model(pretrained_backbone)\n",
    "\t\tif freeze_bn:\n",
    "\t\t\tself._freeze_bn()\n",
    "\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tx, low_feat = self._run_backbone(input)\n",
    "\t\tx = self.aspp(x)\n",
    "\t\tx = self.decoder(x, low_feat)\n",
    "\t\tx = F.interpolate(x, size=input.shape[-2:], mode='bilinear', align_corners=True)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "\tdef _run_backbone_resnet(self, input):\n",
    "\t\t# Stage1\n",
    "\t\tx1 = self.backbone.conv1(input)\n",
    "\t\tx1 = self.backbone.bn1(x1)\n",
    "\t\tx1 = self.backbone.relu(x1)\n",
    "\t\t# Stage2\n",
    "\t\tx2 = self.backbone.maxpool(x1)\n",
    "\t\tx2 = self.backbone.layer1(x2)\n",
    "\t\t# Stage3\n",
    "\t\tx3 = self.backbone.layer2(x2)\n",
    "\t\t# Stage4\n",
    "\t\tx4 = self.backbone.layer3(x3)\n",
    "\t\t# Stage5\n",
    "\t\tx5 = self.backbone.layer4(x4)\n",
    "\t\t# Output\n",
    "\t\treturn x5, x2\n",
    "\n",
    "\n",
    "\tdef _freeze_bn(self):\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.BatchNorm2d):\n",
    "\t\t\t\tm.eval()\n",
    "\n",
    "\n",
    "\tdef _init_weights(self):\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\t\tnn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\t\t\t\tif m.bias is not None:\n",
    "\t\t\t\t\tm.bias.data.zero_()\n",
    "\t\t\telif isinstance(m, nn.BatchNorm2d):\n",
    "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
    "\t\t\t\tnn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet] Initialize weights...\n"
     ]
    }
   ],
   "source": [
    "model = DeepLabV3Plus(backbone='resnet18', num_classes=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_dict = torch.load(\"../src/pretrained/DeepLabV3Plus_ResNet18.pth\", map_location=\"cpu\")['state_dict']\n",
    "model.load_state_dict(trained_dict, strict=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.backbone.state_dict(), \"resnet18_human_seg1.ckpt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}