hydra:
  run:
    dir: .
  hydra_logging: null
  #output_subdir: null
  job_logging: null

# $ python foo.py hydra.run.dir=. hydra.output_subdir=null hydra/job_logging=disabled hydra/hydra_logging=disabled
logging:
  project: alpha-matting
  entity: bsuleymanov
  sample_path: "./sample_path"
  model_save_path: "./models"
  input_image_save_path: "./input_save"
  visual_debug: false
  verbose: 1
  log_step: 100
  sample_step: 1000 # 1000

inference:
  sample_path: "samples_10072021"
  model_load_path: "models_10072021"
  saved_model_name: "98000_network.pth"
  device: cuda
  verbose: 0

data:
  inference:
    transform:
    image_size: 512
    dataloader:
      _target_: src.dataloader.AISegmentInferenceLoader
      image_dir: "../data/to_inference_10072021"
      batch_size: 4
      drop_last: false
      shuffle: false
      num_workers: 8
      image_transform:
        _target_: albumentations.Compose
        transforms:
          - _target_: albumentations.SmallestMaxSize
            max_size: ${.....image_size}
          - _target_: albumentations.RandomCrop
            height: ${.....image_size}
            width: ${.....image_size}
          - _target_: albumentations.Normalize
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
          - _target_: albumentations.pytorch.ToTensorV2


    device: cuda
    saved_model_name: 90000_network.pth

  train:
    #image_path: "../data/dataset_split/train/"
    foreground_csv: "../data/AISegment/train_images.csv"
    matte_csv: "../data/AISegment/train_mattes.csv"
    background_dir: "../data/backgrounds/"
    image_size: 512
    mode: "train"

    #####
    transforms:
      shared_pre:
        _target_: albumentations.Compose
        transforms:
          - _target_: albumentations.SmallestMaxSize
            max_size: ${.....image_size}
          - _target_: albumentations.RandomCrop
            height: ${.....image_size}
            width: ${.....image_size}
      composition: null
#        _target_: albumentations.Normalize
#        mean: [ 0.5, 0.5, 0.5 ]
#        std: [ 0.5, 0.5, 0.5 ]
      foreground:
      background:
      matte: null
      shared_post:
        _target_: albumentations.Compose
        transforms:
          - _target_: albumentations.pytorch.ToTensorV2
    #####

    #####
    dataloader:
      _target_: src.dataloader.AISegmentDistributedLoader
      foreground_csv: ${..foreground_csv}
      matte_csv: ${..matte_csv}
      #foreground_dir: ${..foreground_dir}
      background_dir: ${..background_dir}
      #matte_dir: ${..matte_dir}
      image_size: ${..image_size}
      batch_size: 8
      drop_last: false
      shuffle: true
      num_workers: 8
      bg_per_fg: 1
      mode: ${..mode}
      use_one_img_per_dir: false
      shared_pre_transform: ${..transforms.shared_pre}
      composition_transform: ${..transforms.composition}
      foreground_transform: ${..transforms.foreground}
      background_transform: ${..transforms.background}
      matte_transform: ${..transforms.matte}
      shared_post_transform: ${..transforms.shared_post}
    #####
  validation:
    #image_path: "../data/dataset_split/train/"
    foreground_csv: "../data/AISegment/val_images.csv"
    matte_csv: "../data/AISegment/val_mattes.csv"
    background_dir: "../data/backgrounds/"
    image_size: 512
    mode: "test"

    #####
    transforms:
      shared_pre:
        _target_: albumentations.Compose
        transforms:
          - _target_: albumentations.SmallestMaxSize
            max_size: ${.....image_size}
          - _target_: albumentations.RandomCrop
            height: ${.....image_size}
            width: ${.....image_size}
      composition: null
#        _target_: albumentations.Normalize
#        mean: [ 0.5, 0.5, 0.5 ]
#        std: [ 0.5, 0.5, 0.5 ]
      foreground:
      background:
      matte: null
      shared_post:
        _target_: albumentations.Compose
        transforms:
          - _target_: albumentations.pytorch.ToTensorV2
    #####

    #####
    dataloader:
      _target_: src.dataloader.AISegmentDistributedLoader
      foreground_csv: ${..foreground_csv}
      matte_csv: ${..matte_csv}
      #foreground_dir: ${..foreground_dir}
      background_dir: ${..background_dir}
      #matte_dir: ${..matte_dir}
      image_size: ${..image_size}
      batch_size: 8
      drop_last: false
      shuffle: false
      num_workers: 8
      mode: ${..mode}
      bg_per_fg: 1
      use_one_img_per_dir: false
      shared_pre_transform: ${..transforms.shared_pre}
      composition_transform: ${..transforms.composition}
      foreground_transform: ${..transforms.foreground}
      background_transform: ${..transforms.background}
      matte_transform: ${..transforms.matte}
      shared_post_transform: ${..transforms.shared_post}
    #####

training:
  total_step: 150000
  device: cuda
  loss:
    _target_: src.losses.ModNetLoss
    _recursive_: true
    blurer:
      _target_: src.model.GaussianBlurLayer
      n_channels: 1
      kernel_size: 3
    semantic_scale: 10.0
    detail_scale: 10.0
    matte_scale: 1.0
    average: true
    detailed: false
    device: ${..device}
  parallel: true
  optimizer:
    _target_: torch.optim.Adam
#    _target_: torch.optim.SGD
#    lr: 0.01
#    momentum: 0.9

testing:
  device: cuda

network:
  _target_: src.model.MODNet
  in_channels: 3
  hr_channels: 64
  backbone_arch: "resnet18"
  backbone_pretrained: true
  out_channels: 1